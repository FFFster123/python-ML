{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 导入库"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FFF123\\AppData\\Local\\Temp\\ipykernel_9264\\107850124.py:3: MatplotlibDeprecationWarning: Auto-close()ing of figures upon backend switching is deprecated since 3.8 and will be removed in 3.10.  To suppress this warning, explicitly call plt.close('all') first.\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib  \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 11)  #set default figure size\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import matplotlib.pylab as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:25:59.837612800Z",
     "start_time": "2024-08-17T06:25:59.690310Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 逆预测值（重采样）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# inverse predictive values\n",
    "def inverse_scaler(y_scaled, y_true):   \n",
    "    scaler =MinMaxScaler()              \n",
    "    scaler.fit(np.reshape(yy.values,(len(yy),1)))      \n",
    "    y_inverse = scaler.inverse_transform(y_scaled.reshape(-1,1))       \n",
    "    return y_inverse       "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:25:59.840616Z",
     "start_time": "2024-08-17T06:25:59.693030900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 导入数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datasize: (222, 17)\n",
      "adjusted datasize: (222, 17)\n",
      "data:\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Time  Deep  Length   HRT     COD     TN  NH4-N    C/N    c(A)  CSC  \\\n0      90  12.5    45.0  72.0  299.46  26.80  24.07  11.17  100.00   11   \n1      90  45.0    12.5  72.0  299.46  26.80  24.07  11.17  100.00   11   \n2      84  10.0    30.0  72.0   66.60   3.60   2.35  18.50    0.18   11   \n3      84  10.0    90.0  72.0   66.60   3.60   2.35  18.50    0.18   11   \n4      84  50.0    30.0  72.0   66.60   3.60   2.35  18.50    0.18   11   \n..    ...   ...     ...   ...     ...    ...    ...    ...     ...  ...   \n217    50  20.0    40.0  72.0   60.06  35.83   4.86   1.68    0.00    0   \n218   210  40.0    40.0  48.0  570.32  32.08  20.14  17.78    0.00    0   \n219   210  40.0    40.0  48.0  570.32  32.08  20.14  17.78    0.00    0   \n220   210  40.0    40.0  48.0  570.32  32.08  20.14  17.78    0.00    0   \n221   210  40.0    40.0  48.0  570.32  32.08  20.14  17.78    0.00    0   \n\n     XLogP3   WI    RA(P)    RA(F)    RA(B)    RA(A)  RR(TN)  \n0      -0.1  885  48.0057   1.8966   9.9499   2.3363  0.6451  \n1      -0.1  885  62.3032   1.6632   6.7403   0.9921  0.6451  \n2       0.2  943  50.8357   0.9988  10.7969   7.0869  0.8028  \n3       0.2  943  46.2696   1.4269  11.2249   2.6160  0.8028  \n4       0.2  943  38.7070   0.6659   6.9918   1.5220  0.8028  \n..      ...  ...      ...      ...      ...      ...     ...  \n217     0.0    0  17.1306   6.3166   6.6000   4.9164  0.7311  \n218     0.0    0  57.2920   3.7780  10.2600   4.3550  0.4819  \n219     0.0    0  51.0730   2.2040   4.0930   2.2040  0.5313  \n220     0.0    0  58.2630  11.1570   5.7410   7.0060  0.3772  \n221     0.0    0  44.2250  10.9150   4.3030  10.0760  0.9366  \n\n[222 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>Deep</th>\n      <th>Length</th>\n      <th>HRT</th>\n      <th>COD</th>\n      <th>TN</th>\n      <th>NH4-N</th>\n      <th>C/N</th>\n      <th>c(A)</th>\n      <th>CSC</th>\n      <th>XLogP3</th>\n      <th>WI</th>\n      <th>RA(P)</th>\n      <th>RA(F)</th>\n      <th>RA(B)</th>\n      <th>RA(A)</th>\n      <th>RR(TN)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>90</td>\n      <td>12.5</td>\n      <td>45.0</td>\n      <td>72.0</td>\n      <td>299.46</td>\n      <td>26.80</td>\n      <td>24.07</td>\n      <td>11.17</td>\n      <td>100.00</td>\n      <td>11</td>\n      <td>-0.1</td>\n      <td>885</td>\n      <td>48.0057</td>\n      <td>1.8966</td>\n      <td>9.9499</td>\n      <td>2.3363</td>\n      <td>0.6451</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90</td>\n      <td>45.0</td>\n      <td>12.5</td>\n      <td>72.0</td>\n      <td>299.46</td>\n      <td>26.80</td>\n      <td>24.07</td>\n      <td>11.17</td>\n      <td>100.00</td>\n      <td>11</td>\n      <td>-0.1</td>\n      <td>885</td>\n      <td>62.3032</td>\n      <td>1.6632</td>\n      <td>6.7403</td>\n      <td>0.9921</td>\n      <td>0.6451</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84</td>\n      <td>10.0</td>\n      <td>30.0</td>\n      <td>72.0</td>\n      <td>66.60</td>\n      <td>3.60</td>\n      <td>2.35</td>\n      <td>18.50</td>\n      <td>0.18</td>\n      <td>11</td>\n      <td>0.2</td>\n      <td>943</td>\n      <td>50.8357</td>\n      <td>0.9988</td>\n      <td>10.7969</td>\n      <td>7.0869</td>\n      <td>0.8028</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84</td>\n      <td>10.0</td>\n      <td>90.0</td>\n      <td>72.0</td>\n      <td>66.60</td>\n      <td>3.60</td>\n      <td>2.35</td>\n      <td>18.50</td>\n      <td>0.18</td>\n      <td>11</td>\n      <td>0.2</td>\n      <td>943</td>\n      <td>46.2696</td>\n      <td>1.4269</td>\n      <td>11.2249</td>\n      <td>2.6160</td>\n      <td>0.8028</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84</td>\n      <td>50.0</td>\n      <td>30.0</td>\n      <td>72.0</td>\n      <td>66.60</td>\n      <td>3.60</td>\n      <td>2.35</td>\n      <td>18.50</td>\n      <td>0.18</td>\n      <td>11</td>\n      <td>0.2</td>\n      <td>943</td>\n      <td>38.7070</td>\n      <td>0.6659</td>\n      <td>6.9918</td>\n      <td>1.5220</td>\n      <td>0.8028</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>50</td>\n      <td>20.0</td>\n      <td>40.0</td>\n      <td>72.0</td>\n      <td>60.06</td>\n      <td>35.83</td>\n      <td>4.86</td>\n      <td>1.68</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>17.1306</td>\n      <td>6.3166</td>\n      <td>6.6000</td>\n      <td>4.9164</td>\n      <td>0.7311</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>210</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>48.0</td>\n      <td>570.32</td>\n      <td>32.08</td>\n      <td>20.14</td>\n      <td>17.78</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>57.2920</td>\n      <td>3.7780</td>\n      <td>10.2600</td>\n      <td>4.3550</td>\n      <td>0.4819</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>210</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>48.0</td>\n      <td>570.32</td>\n      <td>32.08</td>\n      <td>20.14</td>\n      <td>17.78</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>51.0730</td>\n      <td>2.2040</td>\n      <td>4.0930</td>\n      <td>2.2040</td>\n      <td>0.5313</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>210</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>48.0</td>\n      <td>570.32</td>\n      <td>32.08</td>\n      <td>20.14</td>\n      <td>17.78</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>58.2630</td>\n      <td>11.1570</td>\n      <td>5.7410</td>\n      <td>7.0060</td>\n      <td>0.3772</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>210</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>48.0</td>\n      <td>570.32</td>\n      <td>32.08</td>\n      <td>20.14</td>\n      <td>17.78</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>44.2250</td>\n      <td>10.9150</td>\n      <td>4.3030</td>\n      <td>10.0760</td>\n      <td>0.9366</td>\n    </tr>\n  </tbody>\n</table>\n<p>222 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MP_data_0323_TN.csv', index_col=None, engine='c') \n",
    "print('original datasize:', df.shape)\n",
    "df.dropna(inplace=True)\n",
    "print('adjusted datasize:', df.shape)\n",
    "print('data:')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:25:59.939918300Z",
     "start_time": "2024-08-17T06:25:59.699764200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 标准化数据，分割训练集，测试集，验证集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "xx= df.iloc[:,0:-1]  # 特征 \n",
    "yy=df.iloc[:,-1]   # 目标变量\n",
    "\n",
    "zscore = StandardScaler()   #用于数据标准化处理的缩放器\n",
    "scaler =MinMaxScaler()   #用于数据最小最大缩放处理的缩放器\n",
    "xx_scaled = zscore.fit_transform(xx)  \n",
    "yy_scaled = scaler.fit_transform(np.reshape(yy.values,(len(yy),1))) \n",
    "\n",
    "def split(xx_scaled, yy_scaled):      #定义一个函数用来划分训练集，测试集，验证集\n",
    "     \n",
    "    x_train, x_test_val, y_train, y_test_val = train_test_split(xx_scaled, yy_scaled, shuffle=True,test_size=0.3, random_state=1)\n",
    "    #x_训练集，x_测试验证集，y_训练集，y_测试验证集                    划分前将数据集进行随机打乱，并按照6：4划分，且划分方式统一\n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_test_val, y_test_val, shuffle=True,test_size=0.25, random_state=1)\n",
    "    #x_测试集，x_验证集，y_测试集，y_验证集                           划分前将数据集进行随机打乱，并按照3：1划分，且划分方式统一\n",
    "    \n",
    "    y2 = yy_scaled.ravel()     #将yy数组转化为一维数组并存在y2中\n",
    "    ind_train = [np.argwhere(y2 == y_train[i])[0].item() for i in range(len(y_train)) if y_train[i] in y2]\n",
    "                                                        #这是一个循环，遍历y_train中的每一个元素，判断y_train中的当前标签y_train[i]是否存在于y2中\n",
    "                #找到y2中所有等于y_train[i]的元素的索引，返回一个二维数组，然后用[0].item()取得第一行赋值给ind_train生成列表\n",
    "    ind_test = [np.argwhere(y2 == y_test[i])[0].item() for i in range(len(y_test)) if y_test[i] in y2]\n",
    "    ind_val = [np.argwhere(y2 == y_val[i])[0].item() for i in range(len(y_val)) if y_val[i] in y2]\n",
    "   \n",
    "    y_train = y_train.ravel()       #将y_train数组转化为一维数组\n",
    "    y_test = y_test.ravel()         #将y_text数组转化为一维数组\n",
    "    y_val = y_val.ravel()           #将y_val数组转化为一维数组\n",
    "    \n",
    "    return x_train, x_test, x_val, y_train, y_test, y_val, xx, yy, np.asarray(ind_train), np.asarray(ind_test), np.asarray(ind_val)\n",
    "    #返回训练集，测试集，验证集的特征数据，和标签（目标变量）数据，原特数据，原目标变量数据，以及转化为数组的ind_train，ind_train，ind_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:25:59.977953Z",
     "start_time": "2024-08-17T06:25:59.721311300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T06:25:59.977953Z",
     "start_time": "2024-08-17T06:25:59.726935800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标变量 is  RR(TN)\n",
      "特征 are  ['Time', 'Deep', 'Length', 'HRT', 'COD', 'TN', 'NH4-N', 'C/N', 'c(A)', 'CSC', 'XLogP3', 'WI', 'RA(P)', 'RA(F)', 'RA(B)', 'RA(A)']\n",
      "样本数量 is  222 ; 预测特征变量 is  16\n",
      "训练集大小 is  155 ; 测试集大小 is  50 ; 验证集大小 is  17\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, x_val, y_train, y_test,y_val, x_scaled, y_scaled, ind_train, ind_test, ind_val = split(xx_scaled, yy_scaled)\n",
    "\n",
    "print('目标变量 is ', yy.name)\n",
    "print('特征 are ', xx.columns.tolist())\n",
    "print('样本数量 is ', xx.shape[0], '; 预测特征变量 is ', xx.shape[1])\n",
    "print('训练集大小 is ', x_train.shape[0], '; 测试集大小 is ', x_test.shape[0],'; 验证集大小 is ', x_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load xgboost model\n",
    "path='Models/'\n",
    "model_name = 'xgb.pkl'\n",
    "with open(path+model_name,'rb') as f:\n",
    "    xgb = pickle.load(f)\n",
    "    \n",
    "y_pred_train = xgb.predict(x_train)\n",
    "y_pred_test = xgb.predict(x_test)    \n",
    "y_pred_val = xgb.predict(x_val) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:25:59.977953Z",
     "start_time": "2024-08-17T06:25:59.734818200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models/gpr.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[65], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModels/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      4\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpr.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      6\u001B[0m     gpr \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m      8\u001B[0m y_pred_train \u001B[38;5;241m=\u001B[39m gpr\u001B[38;5;241m.\u001B[39mpredict(x_train)    \n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:308\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    303\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    304\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    305\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m     )\n\u001B[1;32m--> 308\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Models/gpr.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# load gpr model\n",
    "path='Models/'\n",
    "model_name = 'gpr.pkl'\n",
    "with open(path+model_name,'rb') as f:\n",
    "    gpr = pickle.load(f)\n",
    "    \n",
    "y_pred_train = gpr.predict(x_train)    \n",
    "y_pred_test = gpr.predict(x_test)    \n",
    "y_pred_val = gpr.predict(x_val) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:25:59.977953Z",
     "start_time": "2024-08-17T06:25:59.741774200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ga-Svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load gpr model\n",
    "model_name = 'GA_SVM.pkl'\n",
    "with open(path+model_name,'rb') as f:\n",
    "    ga_svm = pickle.load(f)\n",
    "    \n",
    "y_pred_train = ga_svm.predict(x_train)    \n",
    "y_pred_test = ga_svm.predict(x_test)    \n",
    "y_pred_val = ga_svm.predict(x_val)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.762669800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load rf model\n",
    "path='Models/'\n",
    "model_name = 'rf.pkl'\n",
    "with open(path+model_name,'rb') as f:\n",
    "    rf = pickle.load(f)\n",
    "    \n",
    "y_pred_train = rf.predict(x_train)    \n",
    "y_pred_test = rf.predict(x_test)    \n",
    "y_pred_val = rf.predict(x_val)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.764671700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 敏感性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.766673500Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE(y_test, y_pred_test):\n",
    "    \n",
    "    return mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "mse_value = MSE(y_test, y_pred_test)  \n",
    "print(f'MSE: {mse_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SA_base_on_MSE(model, x_Model, y_Model):\n",
    "    ### stepwise selection II is to set all values of one input variable to its mean (or others) \n",
    "    ### and examine the value of MSE under the change.\n",
    "\n",
    "    SA = pd.Series(index = x_Model.columns, dtype='object'  ) # create a table\n",
    "    x_train, x_test,x_val, y_train, y_test,y_val, x_scaled, y_scaled, ind_train, ind_test,ind_val= split(xx, yy)\n",
    "    # replace one parameter's values into its mean and examine its efficiency\n",
    "\n",
    "    for i in range(0, x_scaled.shape[1]) :\n",
    "        x_test_r = np.array(x_scaled) # copy x_test\n",
    "        x_test_r[:,i] = x_scaled[:,i].mean()\n",
    "        y_re_test=model.predict(x_test_r)\n",
    "        SA[i] = MSE(y_scaled, y_re_test)\n",
    "    return SA\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.767674600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.769676100Z"
    }
   },
   "outputs": [],
   "source": [
    "SA_GA_pred = SA_base_on_MSE(ga_svm,xx,yy)\n",
    "SA_GPR_pred = SA_base_on_MSE(gpr,xx,yy)\n",
    "SA_XGB_pred = SA_base_on_MSE(xgb,xx,yy)\n",
    "SA_RF_pred = SA_base_on_MSE(rf,xx,yy)\n",
    "\n",
    "x = np.arange(len(SA_GA_pred.index))  # the label locations     #SA_RF_pred替换SA_GA_pred\n",
    "width = 0.15  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "rects1 = ax.bar(x - 2*width, SA_GA_pred.values, width, label='GA-SVM')  \n",
    "rects2 = ax.bar(x - width, SA_XGB_pred.values, width, label='XGB')  \n",
    "rects3 = ax.bar(x + width, SA_GPR_pred.values, width, label='GPR')  \n",
    "rects4 = ax.bar(x, SA_RF_pred.values, width, label='RF')  \n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Sensitive Analysis')\n",
    "ax.set_xticks(x)\n",
    "ax.tick_params(axis='x', rotation=0)\n",
    "ax.set_xticklabels(SA_RF_pred.index)  # 假设使用 RF 的索引作为 x 轴标签  \n",
    "plt.grid(False)     # 禁用网格  \n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SA_GA_pred.values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.770677Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobol index with Scipy generate samples"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "bounds = pd.DataFrame(index=xx.columns,columns=['min','max'])\n",
    "bounds['min'] = np.min(xx,0)\n",
    "bounds['max'] = np.max(xx,0)\n",
    "bounds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from SALib.test_functions import Ishigami\n",
    "import numpy as np\n",
    "\n",
    "# Define the problem\n",
    "problem = {\n",
    "    'num_vars': len(xx.columns),\n",
    "    'names': ['Time', 'Deep', 'Length', 'HRT', 'COD', 'TN', 'NH4-N', 'C/N', 'c(A)','CSC','XLogP3','WI','RA(P)','RA(F)','RA(B)','RA(A)'],\n",
    "    'bounds': bounds.values.astype('float')\n",
    "}\n",
    "param_values = saltelli.sample(problem,1024)\n",
    "param_values.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Y1 = rf.predict(param_values)\n",
    "Si1 = sobol.analyze(problem,Y1,print_to_console=True)\n",
    "total_si1,first_si1,second_si1 = Si1.to_df()\n",
    "\n",
    "# 从Si字典中提取总敏感性贡献度（S1）和其他你需要的指标  \n",
    "S1 = Si1['ST']  # 根据SALib的版本和具体实现，这里可能需要调整 \n",
    "\n",
    "# 如果需要，将S1转换为DataFrame  \n",
    "df_sensitivity = pd.DataFrame(S1, index=problem['names'], columns=['ST']) \n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "print(type(df_sensitivity))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 使用正确的列名，通常总敏感性贡献度列名为 'S1'  \n",
    "total_si_column = 'ST'  # 总敏感性贡献度的列名  \n",
    "  \n",
    "# 提取总敏感性贡献度和对应的特征名称  \n",
    "total_si1 = df_sensitivity[total_si_column]  \n",
    "features = df_sensitivity.index.tolist()  # 假设特征名称在索引中  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 确保总敏感性贡献度之和为1，如果不是，则进行归一化处理  \n",
    "total_si1_normalized = total_si1 / total_si1.sum()  \n",
    "  \n",
    "# 绘制饼图  \n",
    "fig, ax = plt.subplots()  \n",
    "ax.pie(total_si1_normalized, labels=features, autopct='%1.1f%%', startangle=90)  \n",
    "  \n",
    "# Equal aspect ratio ensures that pie is drawn as a circle.  \n",
    "ax.axis('equal')    \n",
    "  \n",
    "# 设置标题  \n",
    "plt.title('Feature Contribution to Output Variability')  \n",
    "  \n",
    "# 显示饼图  \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Y2 = xgb.predict(param_values)\n",
    "Si2 = sobol.analyze(problem,Y2,print_to_console=True)\n",
    "total_si2,first_si2,second_si2 = Si2.to_df()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 提取总敏感性贡献度  \n",
    "S1 = total_si2['ST']  \n",
    "  \n",
    "# 创建DataFrame  \n",
    "df_sensitivity = pd.DataFrame(S1, index=problem['names'], columns=['ST'])  \n",
    "  \n",
    "# 归一化总敏感性贡献度  \n",
    "df_sensitivity_normalized = df_sensitivity / df_sensitivity['ST'].sum()  \n",
    "  \n",
    "# 绘制饼图  \n",
    "fig, ax = plt.subplots()  \n",
    "ax.pie(df_sensitivity_normalized['ST'], labels=df_sensitivity.index.tolist(), autopct='%1.1f%%', startangle=90)  \n",
    "ax.axis('equal')  # 确保饼图是圆形  \n",
    "plt.title('Feature Contribution to Output Variability')  \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Y3 = ga_svm.predict(param_values)\n",
    "Si3 = sobol.analyze(problem,Y3,print_to_console=True)\n",
    "total_si3,first_si3,second_si3 = Si3.to_df()\n",
    "\n",
    "# 从Si字典中提取总敏感性贡献度（S1）和其他你需要的指标  \n",
    "S1 = Si3['ST']  # 根据SALib的版本和具体实现，这里可能需要调整 \n",
    "\n",
    "# 如果需要，将S1转换为DataFrame  \n",
    "df_sensitivity = pd.DataFrame(S1, index=problem['names'], columns=['ST']) "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Y4 = gpr.predict(param_values)\n",
    "Si4 = sobol.analyze(problem,Y4,print_to_console=True)\n",
    "total_si4,first_si4,second_si4 = Si4.to_df()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from SALib.test_functions import Ishigami\n",
    "import numpy as np\n",
    "\n",
    "# Define the problem\n",
    "problem = {\n",
    "    'num_vars': len(xx.columns),\n",
    "    'names': ['Time', 'Deep', 'Length', 'HRT', 'COD', 'TN', 'NH4-N', 'C/N', 'c(A)','CSC','XLogP3','WI','RA(P)','RA(F)','RA(B)','RA(A)'],\n",
    "    'bounds': bounds.values.astype('float')\n",
    "}\n",
    "\n",
    "param_values = saltelli.sample(problem,1024)\n",
    "\n",
    "param_values\n",
    "param_values.shape\n",
    "Y_gpr2 = gpr.predict(param_values) \n",
    "Y_svm2 = ga_svm.predict(param_values) \n",
    "Y_rf2 = rf.predict(param_values)\n",
    "Si_gpr2 = sobol.analyze(problem, Y_gpr2, print_to_console=True)\n",
    "Si_svm2 = sobol.analyze(problem, Y_svm2, print_to_console=True)\n",
    "Si_rf2 = sobol.analyze(problem, Y_rf2, print_to_console=True)\n",
    "total_Si_gpr, first_Si_gpr, second_Si_gpr = Si_gpr2.to_df()\n",
    "total_Si_svm, first_Si_svm, second_Si_svm = Si_svm2.to_df()\n",
    "total_Si_rf, first_Si_rf, second_Si_rf = Si_rf2.to_df()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "x = np.arange(len(total_si1.index))  # the label locations   #total_Si_rf替换total_Si_svm\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "rects1 = ax.bar(x-width, abs(first_si3['S1']), width, label='GA-SVM')\n",
    "rects2 = ax.bar(x+width, abs(first_si2['S1']), width, label='XGB')\n",
    "#rects3 = ax.bar(x+width, abs(first_si2['S1']), width, label='GPR')\n",
    "rects4 = ax.bar(x, abs(total_si1['S1']), width, label='RF')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Sobol index')\n",
    "ax.set_title('first sobol values')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(total_si1.index)  #total_Si_rf替换total_Si_svm\n",
    "ax.tick_params(axis='x', rotation=0)  # 这里将旋转角度设置为45度\n",
    "ax.legend(loc='best')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "x = np.arange(len(total_si3.index))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "rects1 = ax.bar(x-width, total_si3['ST'], width, label='GA-SVM')\n",
    "rects2 = ax.bar(x, total_si1['ST'], width, label='RF')\n",
    "rects3 = ax.bar(x+width, total_si2['ST'], width, label='XGB')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Sobol index')\n",
    "ax.set_title('total sobol values')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(total_si3.index)\n",
    "ax.tick_params(axis='x', rotation=0)  # 这里将旋转角度设置为45度\n",
    "ax.legend(loc='best')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "df_sobol = pd.DataFrame(index=SA_GA_pred.index, columns = ['GPR','GA-SVM','RF'])\n",
    "df_sobol['GPR'] = total_si2['ST'].values\n",
    "df_sobol['GA-SVM'] = total_si3['ST'].values\n",
    "df_sobol['RF'] = total_si1['ST'].values\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP (SHapley Additive exPlanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T06:26:00.058532Z",
     "start_time": "2024-08-17T06:25:59.790695700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_shap = pd.DataFrame(index=xx.columns, columns = ['ga_svm','rf','xgb','gpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.794561200Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ga_svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#ga_svm\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m explainer \u001B[38;5;241m=\u001B[39m shap\u001B[38;5;241m.\u001B[39mKernelExplainer(\u001B[43mga_svm\u001B[49m\u001B[38;5;241m.\u001B[39mpredict, x_test)    \n\u001B[0;32m      5\u001B[0m shap_values_ga_svm \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mshap_values(x_test)      \n\u001B[0;32m      6\u001B[0m df_shap[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mga_svm\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage(\u001B[38;5;28mabs\u001B[39m(shap_values_ga_svm),\u001B[38;5;241m0\u001B[39m)   \n",
      "\u001B[1;31mNameError\u001B[0m: name 'ga_svm' is not defined"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "np.random.seed(42)\n",
    "#ga_svm\n",
    "explainer = shap.KernelExplainer(ga_svm.predict, x_test)    \n",
    "shap_values_ga_svm = explainer.shap_values(x_test)      \n",
    "df_shap['ga_svm'] = np.average(abs(shap_values_ga_svm),0)   \n",
    "shap.summary_plot(shap_values_ga_svm,  xx, plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 假设你已经有了每个特征的平均SHAP绝对值  \n",
    "feature_importances = df_shap['ga_svm']  \n",
    "  \n",
    "# 归一化特征重要性，使其和为1  \n",
    "feature_importances_norm = feature_importances / feature_importances.sum()  \n",
    "  \n",
    "# 获取特征名称  \n",
    "feature_names = df_shap.index  \n",
    " \n",
    "# 需要描边的扇形索引列表  \n",
    "wedges_to_highlight = [5,6,7,15]  # 假设你想要突出显示第2、4、6个扇形（索引从0开始）  \n",
    "# 绘制饼状图  \n",
    "fig, ax = plt.subplots()  \n",
    "explode = ( 0.02, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.05)\n",
    "wedges, texts, autotexts = ax.pie(feature_importances_norm, labels=feature_names, autopct='%1.1f%%', pctdistance=0.85, labeldistance=1.1, startangle=-60, radius=0.5, explode=explode, wedgeprops=dict(edgecolor='w', linewidth=1))  # 初始设置所有扇形的描边  \n",
    "# 为特定的扇形设置不同的描边效果  \n",
    "for i in wedges_to_highlight:  \n",
    "    wedges[i].set_edgecolor('black')  # 设置描边颜色为红色  \n",
    "    wedges[i].set_linewidth(2)  # 设置描边宽度为2  \n",
    "\n",
    "ax.axis('equal')  # 确保饼图是圆形的  \n",
    "ax.set_title('Feature Importance-ga_svm', pad=25)  # 设置标题  \n",
    "#plt.savefig('TN_Feature Importance-GA_SVM.png', dpi=500, transparent=True)  # 保存图片到当前目录，dpi参数设置图片分辨率\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.816593500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.818595200Z"
    }
   },
   "outputs": [],
   "source": [
    "#gpr\n",
    "np.random.seed(42)\n",
    "explainer = shap.KernelExplainer(gpr.predict,  x_test)      \n",
    "shap_values_gpr = explainer.shap_values(x_test)             \n",
    "# visualize the first prediction's explanation\n",
    "df_shap['gpr'] = np.average(abs(shap_values_gpr),0)          \n",
    "shap.summary_plot(shap_values_gpr,  xx, plot_type=\"bar\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 假设你已经有了每个特征的平均SHAP绝对值  \n",
    "feature_importances = df_shap['gpr']  \n",
    "# 归一化特征重要性，使其和为1  \n",
    "feature_importances_norm = feature_importances / feature_importances.sum()  \n",
    "# 获取特征名称  \n",
    "feature_names = df_shap.index  \n",
    "\n",
    "# 需要描边的扇形索引列表  \n",
    "wedges_to_highlight = [5,6,7,13,15]  # 假设你想要突出显示第2、4、6个扇形（索引从0开始）  \n",
    "# 绘制饼状图  \n",
    "fig, ax = plt.subplots()  \n",
    "explode = ( 0.02, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.02, 0.05, 0.02, 0.05)\n",
    "wedges, texts, autotexts = ax.pie(feature_importances_norm, labels=feature_names, autopct='%1.1f%%', pctdistance=0.85, labeldistance=1.1, startangle=-45, radius=1, explode=explode)  # 初始设置所有扇形的描边  \n",
    "  \n",
    "# 为特定的扇形设置不同的描边效果  \n",
    "for i in wedges_to_highlight:  \n",
    "    wedges[i].set_edgecolor('black')  # 设置描边颜色为红色  \n",
    "    wedges[i].set_linewidth(2)  # 设置描边宽度为2  \n",
    "\n",
    "ax.axis('equal')  # 确保饼图是圆形的  \n",
    "ax.set_title('Feature Importance-GPR', pad=25)  # 设置标题  \n",
    "#plt.savefig('TN-Feature Importance-GPR.png', dpi=500, transparent=True)  # 保存图片到当前目录，dpi参数设置图片分辨率\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.820597200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c02f35ac582b4edbbf74033722683585"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:952: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  pl.show()\n",
      "C:\\Users\\FFF123\\AppData\\Local\\Temp\\ipykernel_9264\\3664686764.py:13: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "#xgb\n",
    "import shap\n",
    "np.random.seed(42)\n",
    "explainer = shap.KernelExplainer(xgb.predict,  x_test)      #rf替换gpr\n",
    "shap_values_xgb = explainer.shap_values(x_test)             #rf替换gpr\n",
    "# visualize the first prediction's explanation\n",
    "#df_shap['xgb'] = np.average(abs(shap_values_xgb),0)          #rf替换gpr\n",
    "#shap.summary_plot(shap_values_xgb,  xx, plot_type=\"bar\")    #rf替换gpr\n",
    "\n",
    "feature_names = ['Time', 'Deep', 'Length', 'HRT', 'COD', 'TN', 'NH4-N', 'C/N', 'c(A)', 'CSC', 'XLogP3', 'WI', 'RA(P)', 'RA(F)', 'RA(B)', 'RA(A)']  \n",
    "shap.summary_plot(shap_values_xgb, x_test, feature_names=feature_names)\n",
    "ax.set_xlim(-0.30, 0.30)  \n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:26:20.411851100Z",
     "start_time": "2024-08-17T06:26:03.396470100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# 保存为SVG格式  \n",
    "plt.savefig('111XGB-TN-shap_summary_plot.svg',format='svg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:26:25.200303Z",
     "start_time": "2024-08-17T06:26:25.003482200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 假设你已经有了每个特征的平均SHAP绝对值  \n",
    "feature_importances = df_shap['xgb']  \n",
    "# 归一化特征重要性，使其和为1  \n",
    "feature_importances_norm = feature_importances / feature_importances.sum()  \n",
    "# 获取特征名称  \n",
    "feature_names = df_shap.index  \n",
    "\n",
    "# 需要描边的扇形索引列表  \n",
    "wedges_to_highlight = [1,4,7,12]  # 假设你想要突出显示第2、4、6个扇形（索引从0开始）  \n",
    "# 绘制饼状图  \n",
    "fig, ax = plt.subplots()  \n",
    "explode = ( 0.02, 0.05, 0.02, 0.02, 0.05, 0.02, 0.02, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.02, 0.02, 0.02)\n",
    "wedges, texts, autotexts = ax.pie(feature_importances_norm, labels=feature_names, autopct='%1.1f%%', pctdistance=0.85, labeldistance=1.1, startangle=90, radius=0.5, explode=explode)  # 初始设置所有扇形的描边  \n",
    "  \n",
    "# 为特定的扇形设置不同的描边效果  \n",
    "for i in wedges_to_highlight:  \n",
    "    wedges[i].set_edgecolor('black')  # 设置描边颜色为红色  \n",
    "    wedges[i].set_linewidth(2)  # 设置描边宽度为2  \n",
    "\n",
    "ax.axis('equal')  # 确保饼图是圆形的 \n",
    "ax.set_title('Feature Importance-XGB', pad=25)  # 设置标题  \n",
    "#plt.savefig('TN-Feature Importance-RF.png', dpi=500, transparent=True)  # 保存图片到当前目录，dpi参数设置图片分辨率\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.826602600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#rf\n",
    "np.random.seed(42)\n",
    "explainer = shap.KernelExplainer(rf.predict,  x_test)      #rf替换gpr\n",
    "shap_values_rf = explainer.shap_values(x_test)             #rf替换gpr\n",
    "# visualize the first prediction's explanation\n",
    "#df_shap['rf'] = np.average(abs(shap_values_rf),0)          #rf替换gpr\n",
    "#shap.summary_plot(shap_values_rf,  xx,plot_type=\"bar\")    #rf替换gpr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.828604800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shap\n",
    "np.random.seed(42)\n",
    "explainer = shap.KernelExplainer(rf.predict,  x_test)      #rf替换gpr\n",
    "shap_values_rf = explainer.shap_values(x_test)    \n",
    "feature_names = ['Time', 'Deep', 'Length', 'HRT', 'COD', 'TN', 'NH4-N', 'C/N', 'c(A)', 'CSC', 'XLogP3', 'WI', 'RA(P)', 'RA(F)', 'RA(B)', 'RA(A)']  \n",
    "shap.summary_plot(shap_values_rf, x_test, feature_names=feature_names)\n",
    "ax.set_xlim(-0.30, 0.30)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.830606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.831606900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存为SVG格式  \n",
    "plt.savefig('RF-CA-shap_summary_plot.svg',format='svg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.833608700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 假设你已经有了每个特征的平均SHAP绝对值  \n",
    "feature_importances = df_shap['rf']  \n",
    "# 归一化特征重要性，使其和为1  \n",
    "feature_importances_norm = feature_importances / feature_importances.sum()  \n",
    "# 获取特征名称  \n",
    "feature_names = df_shap.index  \n",
    "\n",
    "# 需要描边的扇形索引列表  \n",
    "wedges_to_highlight = [1,4,5,7,12]  # 假设你想要突出显示第2、4、6个扇形（索引从0开始）  \n",
    "# 绘制饼状图  \n",
    "fig, ax = plt.subplots()  \n",
    "explode = ( 0.02, 0.05, 0.02, 0.02, 0.05, 0.05, 0.02, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.02, 0.02, 0.02)\n",
    "wedges, texts, autotexts = ax.pie(feature_importances_norm, labels=feature_names, autopct='%1.1f%%', pctdistance=0.85, labeldistance=1.1, startangle=90, radius=0.5, explode=explode)  # 初始设置所有扇形的描边  \n",
    "  \n",
    "# 为特定的扇形设置不同的描边效果  \n",
    "for i in wedges_to_highlight:  \n",
    "    wedges[i].set_edgecolor('black')  # 设置描边颜色为红色  \n",
    "    wedges[i].set_linewidth(2)  # 设置描边宽度为2  \n",
    "\n",
    "ax.axis('equal')  # 确保饼图是圆形的 \n",
    "ax.set_title('Feature Importance-RF', pad=25)  # 设置标题  \n",
    "#plt.savefig('TN-Feature Importance-RF.png', dpi=500, transparent=True)  # 保存图片到当前目录，dpi参数设置图片分辨率\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.834610500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.835611200Z"
    }
   },
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(xgb)    #rf替换xgbr\n",
    "shap_values_xgb = explainer(x_test)    #rf替换xgbr\n",
    "df_shap['xgb'] = np.average(abs(shap_values_xgb.values),0)    #rf替换xgbr\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.bar(shap_values_xgb)    #rf替换xgbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.836611900Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(len(df_shap.index))  # the label locations\n",
    "width = 0.15  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "rects1 = ax.bar(x - 2*width, df_shap['ga_svm'], width, label='GA-SVM')\n",
    "rects2 = ax.bar(x - width, df_shap['xgb'], width, label='XGB')\n",
    "rects3 = ax.bar(x+width, df_shap['gpr'], width, label='GPR')\n",
    "rects4 = ax.bar(x, df_shap['rf'], width, label='RF')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('shap value')\n",
    "ax.set_title('SHapley Additive exPlanations')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_shap.index)\n",
    "ax.tick_params(axis='x', rotation=0)  # 这里将旋转角度设置为45度\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_shap"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.836611900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.837612800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#   偏相关依赖图PDP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "x_train, x_test_val, y_train, y_test_val = train_test_split(xx, yy, shuffle=True,test_size=0.3, random_state=1)\n",
    "    #x_训练集，x_测试验证集，y_训练集，y_测试验证集                    划分前将数据集进行随机打乱，并按照7：3划分，且划分方式统一\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test_val, y_test_val, shuffle=True,test_size=0.25, random_state=1)\n",
    "    #x_测试集，x_验证集，y_测试集，y_验证集                           划分前将数据集进行随机打乱，并按照3：1划分，且划分方式统一\n",
    "    \n",
    "feature_names = ['Time', 'Deep', 'Length', 'HRT', 'COD', 'TN', 'NH4-N', 'C/N', 'c(A)', 'CSC', 'XLogP3', 'WI', 'RA(P)', 'RA(F)', 'RA(B)', 'RA(A)']  \n",
    "\n",
    "feat_name = ('Time')\n",
    "PartialDependenceDisplay.from_estimator(rf, x_train, [feat_name])\n",
    "plt.gcf().set_size_inches(6, 6)  # w 是宽度，h 是高度  \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.838614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "f_names = [('XLogP3', 'RA(A)')]\n",
    "# Similar to previous PDP plot except we use tuple of features instead of single feature\n",
    "disp4 = PartialDependenceDisplay.from_estimator(rf,x_test, f_names, ax=ax)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T06:25:59.839614800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
